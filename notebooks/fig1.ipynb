{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from scipy.stats import percentileofscore, norm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from rasterio import features\n",
    "from affine import Affine\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "from cartopy.mpl import geoaxes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grid_cell_areas(ds, lat_name=\"lat\", lon_name=\"lon\", r_earth=6.371e6):\n",
    "    \"\"\"\n",
    "    Calculate the area (in km^2) of DataSet or DataArray grid cells, using the following formula:\n",
    "    A = r^2 * (lon1 - lon0) * (sin(lat1) - sin(lat0))\n",
    "    where r is the radius of the earth, lon1 and lon0 are the max and min bounds of the grid cell along the x-axis, lat1 and lat0\n",
    "    along the y-axis.\n",
    "    Note: currently assumes coordinates refer to center of grid cells (but not necessarily that they're evenly spaced)\n",
    "    \"\"\"\n",
    "    def get_bounds(coords_1d):\n",
    "        \"\"\"\n",
    "        Calculates boundaries of grid cells in one dimension\n",
    "        \"\"\"\n",
    "        diffs = np.diff(coords_1d)\n",
    "        diffs = np.insert(diffs, 0, diffs[0])\n",
    "        diffs = np.append(diffs, diffs[-1])\n",
    "        min_bounds = coords_1d - diffs[:-1] / 2\n",
    "        max_bounds = coords_1d + diffs[1:] / 2\n",
    "        return np.array([min_bounds, max_bounds]).transpose()\n",
    "    # get boundaries of grid cells, convert to radians\n",
    "    lat_bounds = get_bounds(ds[lat_name])\n",
    "    lat_bounds_rad = np.deg2rad(lat_bounds)\n",
    "    lon_bounds = get_bounds(ds[lon_name])\n",
    "    lon_bounds_rad = np.deg2rad(lon_bounds)\n",
    "    # get widths and heights (in radians) of grid cells\n",
    "    y_lens = np.sin(lat_bounds_rad[:, 1]) - np.sin(lat_bounds_rad[:, 0])\n",
    "    x_lens = lon_bounds_rad[:, 1] - lon_bounds_rad[:, 0]\n",
    "    # calculate areas in km^2 given widths and heights in radians\n",
    "    areas = (r_earth ** 2) * np.outer(y_lens, x_lens)\n",
    "    area_da = xr.DataArray(areas, coords=[ds[lat_name],ds[lon_name]], dims=[\"lat\", \"lon\"])\n",
    "    return area_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wy(dates):\n",
    "    wys = []\n",
    "    for date in dates:\n",
    "        if date.month >= 10:\n",
    "            wys.append(date.year+1)\n",
    "        else:\n",
    "            wys.append(date.year)\n",
    "    return wys\n",
    "    \n",
    "def get_dowy(dates):\n",
    "    days = []\n",
    "    for date in dates:\n",
    "        if date.month >= 10:\n",
    "            dowy = date.dayofyear - pd.to_datetime(f\"{date.year}-10-01\").dayofyear + 1\n",
    "        else: \n",
    "            dowy = date.dayofyear + 92\n",
    "        if date.year % 4 == 0 and dowy>=92+61:\n",
    "            dowy = dowy -1\n",
    "        days.append(dowy)\n",
    "    return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_from_latlon(lat, lon):\n",
    "    lat = np.asarray(lat)\n",
    "    lon = np.asarray(lon)\n",
    "    trans = Affine.translation(lon[0], lat[0])\n",
    "    scale = Affine.scale(lon[1] - lon[0], lat[1] - lat[0])\n",
    "    return trans * scale\n",
    "\n",
    "def rasterize(shapes, coords, fill=np.nan, **kwargs):\n",
    "    \"\"\"Rasterize a list of (geometry, fill_value) tuples onto the given\n",
    "    xarray coordinates. This only works for 1d latitude and longitude\n",
    "    arrays.\n",
    "    \"\"\"\n",
    "    transform = transform_from_latlon(coords['lat'], coords['lon'])\n",
    "    out_shape = (len(coords['lat']), len(coords['lon']))\n",
    "    raster = features.rasterize(shapes, out_shape=out_shape,\n",
    "                                fill=fill, transform=transform,\n",
    "                                dtype=float, **kwargs)\n",
    "    return xr.DataArray(raster, coords=coords, dims=('lat', 'lon'))\n",
    "    \n",
    "\n",
    "# uaz = uaz.assign(basin=((\"lat\",\"lon\"),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive(data, stepsize=1):\n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_BASIN = \"COLUMBIA\"\n",
    "PLOT_YEAR = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/dartfs-hpc/rc/lab/C/CMIG\"\n",
    "data_dir = os.path.join(root_dir, \"agottlieb\", 'git_repos',\"snow_drought\", \"data\")\n",
    "fig_dir = os.path.join(root_dir, \"agottlieb\", 'git_repos',\"snow_drought\", \"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snotel_dir = os.path.join(data_dir,'basin','SNOTEL')\n",
    "snotel_files = [os.path.join(snotel_dir,f) for f in os.listdir(snotel_dir)]\n",
    "snotel_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load basin boundaries\n",
    "grdc_basins = gpd.read_file(os.path.join(data_dir, \"boundaries\", \"grdc_basins\"), layer=\"mrb_basins\")\n",
    "basin_ids = {k: i for i, k in zip(grdc_basins.index,grdc_basins.RIVER_BASI)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SNOTEL basin-average data\n",
    "snotel_basin = xr.open_mfdataset(snotel_files)\n",
    "snotel_basin = snotel_basin.sel(time=snotel_basin['time'][~((snotel_basin['time.month']==2)&(snotel_basin['time.day']==29))])\n",
    "snotel_basin = snotel_basin.assign(dowy=(('time'),get_dowy(pd.to_datetime(snotel_basin['time'].values))))\n",
    "snotel_basin = snotel_basin.assign(wy=(('time'),get_wy(pd.to_datetime(snotel_basin['time'].values))))\n",
    "\n",
    "# subset out basin of interest\n",
    "plot_basin_data = snotel_basin.sel(basin=basin_ids[PLOT_BASIN]).load()\n",
    "\n",
    "# calculate standardized SWEI, group into bins\n",
    "plot_basin_data[\"SWEI\"] = plot_basin_data[\"SWE\"].rolling(time=90).sum().groupby(\"time.dayofyear\").apply(lambda x: norm.ppf((x.rank(\"time\")-0.44)/(x.count(\"time\")+0.12)))\n",
    "swei_thresh = [-np.inf, -2, -1.6, -1.3, -0.8, -0.5, 0.5, 0.8, 1.3, 1.6, 2, np.inf]\n",
    "def swei_class(x):\n",
    "    return pd.cut(x, bins=swei_thresh, labels=np.arange(-5,6)) # -5 = D4, 0=NN\n",
    "plot_basin_data[\"SWEI_class\"] = xr.apply_ufunc(swei_class, plot_basin_data[\"SWEI\"])\n",
    "\n",
    "# subset out year of interest\n",
    "year_plot_data = plot_basin_data.sel(time=plot_basin_data[\"time\"][plot_basin_data[\"wy\"]==PLOT_YEAR])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get climatology for each DOWY\n",
    "plot_pct_clim = year_plot_data['SWE_pct_med'].values\n",
    "\n",
    "plot_peak = plot_basin_data['SWE'].resample(time=\"AS-OCT\").max() # get peak SWE\n",
    "plot_apr1 = plot_basin_data['SWE'].sel(time=plot_basin_data[\"time\"][(plot_basin_data[\"time.month\"]==4) & (plot_basin_data[\"time.day\"]==1)]) # get April 1 SWE\n",
    "\n",
    "dps = plot_basin_data[\"SWE\"].groupby(plot_basin_data[\"wy\"]).apply(lambda x: x.idxmax()) # get date of peak SWE in each WY\n",
    "dps.values = np.array(get_dowy(pd.to_datetime(dps.values))) # convert to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert DataArrays to DataFrames\n",
    "plot_basin_df = plot_basin_data.to_dataframe().reset_index()\n",
    "plot_basin_clim_df = plot_basin_data.groupby(plot_basin_data[\"dowy\"]).mean().to_dataframe().reset_index().set_index(\"dowy\")\n",
    "plot_apr1_df = plot_apr1.to_dataframe().reset_index()\n",
    "plot_peak_df = plot_peak.to_dataframe().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate heatmap for percentiles of different metrics\n",
    "defs = [\"SWE\", \"SWEI\", \"Apr 1 SWE\", \"Peak SWE\", \"Date of\\nPeak SWE\"]\n",
    "heatmap_df = pd.DataFrame(index=defs,columns=plot_basin_data[\"time\"].values)\n",
    "\n",
    "# continuous measures \n",
    "for idx, row in plot_basin_df.iterrows():\n",
    "    heatmap_df.at[\"SWE\", row[\"time\"]] = percentileofscore(plot_basin_df.loc[plot_basin_df.dowy==row.dowy, \"SWE\"], row[\"SWE\"]) # peak SWE\n",
    "heatmap_df.loc[\"SWEI\"] = 100*norm.cdf(plot_basin_df[\"SWEI\"].values) # convert SWEI back to percentile \n",
    "\n",
    "# yearly metrics\n",
    "for wy in range(1981,2021):\n",
    "    heatmap_df.loc[\"Apr 1 SWE\", f\"{wy-1}-10-01\":f\"{wy}-09-30\"] = percentileofscore(plot_apr1.values, plot_apr1.sel(time=f\"{wy}-04-01\").values)\n",
    "    heatmap_df.loc[\"Peak SWE\", f\"{wy-1}-10-01\":f\"{wy}-09-30\"] = percentileofscore(plot_peak.values, plot_peak.sel(time=f\"{wy-1}-10-01\").values)\n",
    "    heatmap_df.loc[\"Date of\\nPeak SWE\", f\"{wy-1}-10-01\":f\"{wy}-09-30\"] = percentileofscore(dps.values, dps.sel(wy=wy).values)\n",
    "heatmap_df.columns.name=\"\"\n",
    "heatmap_df = heatmap_df.astype(float)\n",
    "heatmap_df = heatmap_df.loc[:, \"1980-10-01\":\"2020-09-30\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate binary heatmap for when each other would identify a snow drought\n",
    "author_defs = [\"D19\",\"H17\",\"HM17\",\"HA20\",\"M19-Low\",\"M19-Early\"]\n",
    "author_df = pd.DataFrame(index=author_defs,columns=plot_basin_data[\"time\"].values)\n",
    "\n",
    "# Hatchett and McEvory (2017): daily SWE below clim. median\n",
    "for idx, row in plot_basin_df.iterrows():\n",
    "    author_df.at[\"HM17\", row[\"time\"]] = (row[\"SWE\"] / plot_basin_clim_df.loc[row.dowy, \"SWE\"]) < 1\n",
    "    \n",
    "# Huning and AghaKouchak (2020): SWEI < -0.8\n",
    "author_df.loc[\"HA20\"] = (plot_basin_df[\"SWEI\"] < -0.8).values\n",
    "\n",
    "# Harpold et al. (2017): sub-normal April 1 SWEfor idx, row in plot_apr1_df.iterrows():\n",
    "for idx, row in plot_apr1_df.iterrows():\n",
    "    author_df.loc[\"H17\", f\"{row.time.year-1}-10-01\":f\"{row.time.year}-09-30\"] = (row[\"SWE\"]/plot_apr1_df[\"SWE\"].mean()) < 1\n",
    "\n",
    "for idx, row in plot_peak_df.iterrows():\n",
    "    yr = row.time.year\n",
    "    # Marshall et al. (2019): peak SWE < 25th %ile\n",
    "    author_df.loc[\"M19-Low\", f\"{yr}-10-01\":f\"{yr+1}-09-30\"] = percentileofscore(plot_peak_df[\"SWE\"],row[\"SWE\"]) < 25\n",
    "    # Dierauer et al. (2019): sub-normal peak SWE\n",
    "    author_df.loc[\"D19\", f\"{yr}-10-01\":f\"{yr+1}-09-30\"] = (row[\"SWE\"] / plot_peak_df[\"SWE\"].mean()) < 1\n",
    "    \n",
    "# Marshall et al. (2019): date of peak SWE < 25th %ile\n",
    "for y in range(dps[\"wy\"].min().values,dps[\"wy\"].max().values):\n",
    "    author_df.loc[\"M19-Early\", f\"{y-1}-10-01\":f\"{y}-09-30\"] = percentileofscore(dps.values,dps.sel(wy=y).values) < 25\n",
    "author_df.columns.name=\"\"\n",
    "author_df = author_df.astype(float)\n",
    "author_df = author_df.loc[:,\"1980-10-01\":\"2020-09-30\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2,\n",
    "        style=\"ticks\")\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': False, \"hatch.color\": \"black\"})\n",
    "\n",
    "fig = plt.figure(figsize=(30,12))\n",
    "gs = gridspec.GridSpec(ncols=2, nrows=11, width_ratios=[3.5,6.5], figure=fig)\n",
    "\n",
    "#################\n",
    "### Figure 2a ###\n",
    "#################\n",
    "\n",
    "ax = plt.subplot(gs[:9,0])\n",
    "\n",
    "# plot climatological SWE\n",
    "sns.lineplot(x=plot_basin_clim_df.index, y=plot_basin_clim_df[\"SWE\"].values, lw=3, color=\"black\",legend=False, ax=ax)\n",
    "for line in ax.lines:\n",
    "    line.set_linestyle(\"--\") # change linestyle\n",
    "# plot WY 2015 SWE\n",
    "sns.lineplot(x=year_plot_data['dowy'], y=year_plot_data[\"SWE\"].values, alpha=0.7, lw=5, color=\"black\",legend=False, ax=ax)\n",
    "ax.set_ylim(0,600)\n",
    "ax.set_xlim(0,365)\n",
    "ax.set_xticks([0, 31, 61, 92, 123, 151, 182, 212, 243, 273, 304, 334]) # add axis ticks for start of each month\n",
    "ax.set_xticklabels([\"O\", \"N\", \"D\", \"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\"])\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.set_ylabel(r\"Basin-average SWE (mm)\")\n",
    "ax.title.set_text(\"Columbia River Basin, WY 2015\")\n",
    "\n",
    "# get values to determine regions for shading/hatching\n",
    "swe_clim = plot_basin_clim_df[\"SWE\"].values\n",
    "swe_yr = np.pad(year_plot_data[\"SWE\"].values,(0,len(swe_clim)-len(year_plot_data['time'])),mode='constant',constant_values=0)\n",
    "\n",
    "\n",
    "\n",
    "swei_sd = year_plot_data[\"SWEI_class\"].values\n",
    "swei_colors = [mpl.cm.RdYlBu(x) for x in np.linspace(0,1,len(swei_thresh)-1)]\n",
    "swei_colors[5] = (1,1,1,1)\n",
    "for d in np.arange(-5,6): # for each SWEI-based snow drought class...\n",
    "    if d == 0:\n",
    "        continue\n",
    "    xs = np.where(swei_sd==d)[0] # ...get indices for dates where you're in each drought class\n",
    "    if len(xs) == 0:\n",
    "        continue    \n",
    "    elif d < 0:\n",
    "        for x_range in consecutive(xs):\n",
    "            ax.fill_between(x_range,swe_clim[x_range],swe_yr[x_range], color=swei_colors[d+5]) # shade area between year curve and clim. curve according to drought class\n",
    "    elif d > 0:\n",
    "        for x_range in consecutive(xs):\n",
    "            ax.fill_between(x_range,swe_yr[x_range],swe_clim[x_range], color=swei_colors[d+5]) # do the same for abnormally wet\n",
    "            \n",
    "ax.fill_between(plot_basin_clim_df.index.values,swe_clim,swe_yr,where=swe_yr<swe_clim,facecolor=\"none\",edgecolor=\"black\",hatch=\"/\") # hatch area where SWE < clim.\n",
    "\n",
    "# add text showing peak, date of peak, and 1 Apr values and percentiles\n",
    "ax.axvline(x=swe_yr.argmax(),ymin=0,ymax=swe_yr.max()/600,color=\"blue\",lw=3)\n",
    "ax.axhline(y=swe_yr.max(),xmin=(swe_yr.argmax()+1)/365, xmax=1, clip_on=False,color=\"blue\",lw=3)\n",
    "\n",
    "ax.axvline(x=182,ymin=0,ymax=swe_yr[182]/600,color=\"red\",lw=3)\n",
    "ax.axhline(swe_yr[182],xmin=182/365,xmax=1,color=\"red\",lw=3)\n",
    "\n",
    "ax.text(x=245,y=swe_yr.max()+20,s=f\"Peak:\\n{int(100*swe_yr.max()/plot_peak_df['SWE'].mean())}% clim.\\nRecord low\", color=\"blue\")\n",
    "ax.text(x=268,y=swe_yr[182]-100,s=f\"Apr 1:\\n{int(100*swe_yr[182]/plot_apr1_df['SWE'].mean())}% clim.\\nRecord low\", color=\"red\")\n",
    "\n",
    "\n",
    "# add imset showing where basin is in upper-left corner\n",
    "stamen_terrain = cimgt.Stamen('terrain-background')\n",
    "states_provinces = cartopy.feature.NaturalEarthFeature(\n",
    "    category='cultural',\n",
    "    name='admin_1_states_provinces_lines',\n",
    "    scale='50m',\n",
    "    facecolor='none')\n",
    "ax_ins = inset_axes(ax, width=\"35%\",height=\"50%\",\n",
    "                    loc=\"upper left\",\n",
    "                    bbox_to_anchor=(0,0.25,0.8,0.8),\n",
    "                    bbox_transform=ax.transAxes,\n",
    "                    axes_class=geoaxes.GeoAxes,\n",
    "                    axes_kwargs=dict(map_projection=cartopy.crs.PlateCarree()))\n",
    "bounds = grdc_basins[grdc_basins.RIVER_BASI==PLOT_BASIN].geometry.total_bounds\n",
    "ax_ins.set_extent([bounds[0]-2, bounds[2]+2, bounds[1]-2,bounds[3]+2], crs=ccrs.PlateCarree())\n",
    "ax_ins.add_image(stamen_terrain, 8)\n",
    "grdc_basins[grdc_basins[\"RIVER_BASI\"]==PLOT_BASIN].geometry.boundary.plot(ax=ax_ins, transform=ccrs.PlateCarree(),color=\"r\") # add basin outline\n",
    "ax_ins.add_feature(states_provinces, edgecolor='black',lw=0.5) # add state/province outlines\n",
    "ax_ins.add_feature(cartopy.feature.BORDERS,edgecolor='black')\n",
    "\n",
    "# snotel_stns = pd.read_csv(os.path.join(root_dir,'SNOTEL','station_meta.csv'))\n",
    "# snotel_stns['geometry'] = snotel_stns.apply(lambda x: Point(x['lon'],x[' lat']),axis=1)\n",
    "# snotel_stns = gpd.GeoDataFrame(snotel_stns)\n",
    "# snotel_stns = gpd.overlay(snotel_stns,grdc_basins)\n",
    "# basin_stns = snotel_stns[snotel_stns['RIVER_BASI']==PLOT_BASIN]\n",
    "# basin_stns.plot(ax=ax_ins)\n",
    "\n",
    "# create colorbar for SWEI-based snow drought classifications\n",
    "cmap = mpl.colors.ListedColormap(swei_colors)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=mpl.colors.BoundaryNorm(np.linspace(0,100,len(swei_thresh)), len(swei_colors)))\n",
    "sm.set_array([])\n",
    "cax = plt.subplot(gs[10,0])\n",
    "cbar = fig.colorbar(sm, cax=cax, orientation=\"horizontal\",use_gridspec=True,aspect=50)\n",
    "cbar.ax.set_xlabel(\"SWEI-based Snow Drought Classification\", rotation=0, labelpad=5)\n",
    "# cbar.ax.set_xticklabels(mos)\n",
    "tick_locs = np.linspace(5,95,len(swei_colors))\n",
    "cbar.set_ticks(tick_locs)\n",
    "swei_labels = [\"D4\", \"D3\", \"D2\", \"D1\", \"D0\", \"NN\", \"W0\", \"W1\", \"W2\", \"W3\", \"W4\"]\n",
    "cbar.set_ticklabels(swei_labels)\n",
    "\n",
    "#################\n",
    "### Figure 2b ###\n",
    "#################\n",
    "ax3 = plt.subplot(gs[:4,1])\n",
    "\n",
    "# plot heatmap for percentiles of each metric\n",
    "heatmap_cmap = plt.cm.get_cmap(\"RdBu\", 10)\n",
    "sns.heatmap(heatmap_df,cmap=heatmap_cmap,vmin=0,vmax=100,cbar=False,ax=ax3)\n",
    "\n",
    "# center x-ticks on 1 April (halfway through WY)\n",
    "ax3.set_xticks(np.where((heatmap_df.columns.month==4) & (heatmap_df.columns.day==1))[0])\n",
    "ax3.set_xticklabels(np.arange(heatmap_df.columns[0].year+1,heatmap_df.columns[-1].year+1), rotation=-60)\n",
    "\n",
    "# only show every other year\n",
    "for label in ax3.xaxis.get_ticklabels()[1::2]:\n",
    "    label.set_visible(False)\n",
    "# rotate definitions\n",
    "defs[4] = \"Date of\\nPeak SWE\"\n",
    "ax3.set_yticklabels(defs,rotation=0)\n",
    "\n",
    "# add thicker horizontal lines between definitions, thicker still on top and bottom\n",
    "ax3.hlines(np.arange(1,len(defs)+1), *ax3.get_xlim(),linewidth=4)\n",
    "ax3.hlines([0,len(defs)+1], *ax3.get_xlim(),linewidth=10)\n",
    "\n",
    "# add thicker vertical lines between WY (every 1 October), thicker still on left and right\n",
    "ax3.vlines(np.where((heatmap_df.columns.month==10) & (heatmap_df.columns.day==1))[0], *ax3.get_ylim(),linewidth=4)\n",
    "ax3.vlines([0,heatmap_df.shape[1]], *ax3.get_xlim(),linewidth=10)\n",
    "\n",
    "# add colorbar of deciles for definitions\n",
    "sm = plt.cm.ScalarMappable(cmap=heatmap_cmap, norm=mpl.colors.BoundaryNorm(np.linspace(0,100,11), heatmap_cmap.N))\n",
    "sm.set_array([])\n",
    "# cax2 = inset_axes(ax3, width=\"10%\", height=\"100%\", bbox_to_anchor=(0.86, 1.23, 0.2, 1), bbox_transform=ax3.transAxes)\n",
    "cax2 = plt.subplot(gs[5,1])\n",
    "cbar = fig.colorbar(sm, cax=cax2, orientation=\"horizontal\", ticks=np.arange(0,101,10), pad=0.15, use_gridspec=True)\n",
    "cbar.ax.set_xlabel(\"Percentile\")\n",
    "cbar.ax.set_yticklabels(np.arange(0,105,10))\n",
    "\n",
    "#################\n",
    "### Figure 2c ###\n",
    "#################\n",
    "\n",
    "ax4 = plt.subplot(gs[7:, 1])\n",
    "\n",
    "# plot binary heatmap of author definitions\n",
    "sns.heatmap(author_df,cmap=\"Greys\",vmin=0,vmax=1.5,cbar=False,ax=ax4)\n",
    "\n",
    "# center x-ticks on 1 April (halfway through WY)\n",
    "ax4.set_xticks(np.where((author_df.columns.month==4) & (author_df.columns.day==1))[0])\n",
    "ax4.set_xticklabels(np.arange(author_df.columns[0].year+1,author_df.columns[-1].year+1), rotation=-60)\n",
    "ax4.set_yticklabels(author_defs, va=\"center\",rotation=0)\n",
    "\n",
    "# only show every other year\n",
    "for label in ax4.xaxis.get_ticklabels()[1::2]:\n",
    "    label.set_visible(False)\n",
    "    \n",
    "ax4.set_xlabel(\"Water year\")\n",
    "ax4.set_ylabel(\"Author\",labelpad=-30)\n",
    "\n",
    "# add thicker horizontal lines between definitions, thicker still on top and bottom\n",
    "ax4.hlines([1,2,3,4,5], *ax4.get_xlim(),linewidth=4)\n",
    "ax4.hlines([0,6], *ax4.get_xlim(),linewidth=10)\n",
    "\n",
    "# add thicker vertical lines between WY (every 1 October), thicker still on left and right\n",
    "ax4.vlines(np.where((author_df.columns.month==10) & (author_df.columns.day==1))[0], *ax4.get_ylim(),linewidth=4)\n",
    "ax4.vlines([0,author_df.shape[1]], *ax4.get_xlim(),linewidth=10)\n",
    "\n",
    "# add subplot labels\n",
    "fig.text(0.1,0.9,\"a\",fontsize=28,fontweight=\"bold\")\n",
    "fig.text(0.42,0.9,\"b\",fontsize=28,fontweight=\"bold\")\n",
    "fig.text(0.42,0.4,\"c\",fontsize=28,fontweight=\"bold\")\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,\"fig1.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arg",
   "language": "python",
   "name": "arg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
