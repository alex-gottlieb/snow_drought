{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from itertools import combinations\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rasterio import features\n",
    "from affine import Affine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_from_latlon(lat, lon):\n",
    "    lat = np.asarray(lat)\n",
    "    lon = np.asarray(lon)\n",
    "    trans = Affine.translation(lon[0], lat[0])\n",
    "    scale = Affine.scale(lon[1] - lon[0], lat[1] - lat[0])\n",
    "    return trans * scale\n",
    "\n",
    "def rasterize(shapes, coords, fill=np.nan, **kwargs):\n",
    "    \"\"\"Rasterize a list of (geometry, fill_value) tuples onto the given\n",
    "    xarray coordinates. This only works for 1d latitude and longitude\n",
    "    arrays.\n",
    "    \"\"\"\n",
    "    transform = transform_from_latlon(coords['lat'], coords['lon'])\n",
    "    out_shape = (len(coords['lat']), len(coords['lon']))\n",
    "    raster = features.rasterize(shapes, out_shape=out_shape,\n",
    "                                fill=fill, transform=transform,\n",
    "                                dtype=float, **kwargs)\n",
    "    return xr.DataArray(raster, coords=coords, dims=('lat', 'lon'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/dartfs-hpc/rc/lab/C/CMIG\"\n",
    "data_dir = os.path.join(root_dir, \"agottlieb\", \"git_repos\", \"snow_drought\", \"data\")\n",
    "gridded_dir = os.path.join(data_dir,'gridded')\n",
    "basin_dir = os.path.join(data_dir,'basin')\n",
    "fig_dir = os.path.join(root_dir, \"agottlieb\", \"git_repos\",\"snow_drought\", \"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get peak SWE from each gridded data product\n",
    "if not os.path.exists(os.path.join(data_dir,'gridded_peak_ensemble.nc')):\n",
    "    gridded_peak_ensemble = []\n",
    "    for prod in os.listdir(gridded_dir):\n",
    "        prod_dir = os.path.join(gridded_dir,prod)\n",
    "        prod_files = [os.path.join(prod_dir,f) for f in os.listdir(prod_dir)]\n",
    "        prod_files.sort()\n",
    "        prod_peak = []\n",
    "        for f in prod_files:\n",
    "            with xr.open_dataset(f) as ds:\n",
    "                prod_peak.append(ds['SWE'].resample(time='AS-OCT').max())\n",
    "        prod_peak = xr.concat(prod_peak,dim='time')\n",
    "        prod_peak = prod_peak.assign_coords(product=prod)\n",
    "        gridded_peak_ensemble.append(prod_peak)\n",
    "        print(prod)\n",
    "    gridded_peak_ensemble = xr.concat(gridded_peak_ensemble,dim='product')\n",
    "    gridded_peak_ensemble.name = 'peak_swe'\n",
    "    gridded_peak_ensemble = gridded_peak_ensemble.to_dataset()\n",
    "    gridded_peak_ensemble.to_netcdf(os.path.join(data_dir,'gridded_peak_ensemble.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(data_dir,'gridded_corr.nc')):\n",
    "    def pairwise_corr(X1,X2):\n",
    "        try:\n",
    "            r, p = spearmanr(X1,X2,nan_policy=\"omit\")\n",
    "            return r,p\n",
    "        except:\n",
    "            return np.nan, np.nan\n",
    "        \n",
    "    gridded_peak_ensemble = xr.open_dataset(os.path.join(data_dir,'gridded_peak_ensemble.nc'))\n",
    "    product_combos = list(combinations(gridded_peak_ensemble[\"product\"].values,2)) # generate all combinations of 2 products\n",
    "    rs = []\n",
    "    ps = []\n",
    "    for combo in product_combos:\n",
    "        X1 = gridded_peak_ensemble.sel(product=combo[0])['peak_swe']\n",
    "        X2 = gridded_peak_ensemble.sel(product=combo[1])['peak_swe']\n",
    "        r, p = xr.apply_ufunc(pairwise_corr,X1,X2,input_core_dims=[['time'],['time']],output_core_dims=[[],[]],vectorize=True)\n",
    "        r = r.assign_coords(combo=\"+\".join(combo))\n",
    "        p = p.assign_coords(combo=\"+\".join(combo))\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "        print(combo, \"complete\")\n",
    "    rs = xr.concat(rs,dim='combo')\n",
    "    ps = xr.concat(ps,dim='combo')\n",
    "    rs.name = 'r'\n",
    "    ps.name = 'p'\n",
    "    corr_ds = xr.merge([rs,ps])\n",
    "    corr_ds.to_netcdf(os.path.join(data_dir,'gridded_corr.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get peak SWE from each basin data product\n",
    "if not os.path.exists(os.path.join(data_dir,'basin_peak_ensemble.nc')):\n",
    "    basin_peak_ensemble = []\n",
    "    for prod in os.listdir(basin_dir):\n",
    "        prod_dir = os.path.join(basin_dir,prod)\n",
    "        prod_files = [os.path.join(prod_dir,f) for f in os.listdir(prod_dir)]\n",
    "        prod_files.sort()\n",
    "        prod_peak = []\n",
    "        for f in prod_files:\n",
    "            with xr.open_dataset(f) as ds:\n",
    "                prod_peak.append(ds['SNOMAS'].resample(time='AS-OCT').max())\n",
    "        prod_peak = xr.concat(prod_peak,dim='time')\n",
    "        prod_peak = prod_peak.assign_coords(product=prod)\n",
    "        basin_peak_ensemble.append(prod_peak)\n",
    "        print(prod)\n",
    "    basin_peak_ensemble = xr.concat(basin_peak_ensemble,dim='product')\n",
    "    basin_peak_ensemble.name = 'peak_swe'\n",
    "    basin_peak_enesemble = basin_peak_ensemble.to_dataset()\n",
    "    basin_peak_ensemble.to_netcdf(os.path.join(data_dir,'basin_peak_ensemble.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(data_dir,'basin_corr.nc')):\n",
    "    def pairwise_corr(X1,X2):\n",
    "        try:\n",
    "            r, p = spearmanr(X1,X2,nan_policy=\"omit\")\n",
    "            return r,p\n",
    "        except:\n",
    "            return np.nan, np.nan\n",
    "        \n",
    "    basin_peak_ensemble = xr.open_dataset(os.path.join(data_dir,'basin_peak_ensemble.nc'))\n",
    "    product_combos = list(combinations(basin_peak_ensemble[\"product\"].values,2)) # generate all combinations of 2 products\n",
    "    rs = []\n",
    "    ps = []\n",
    "    for combo in product_combos:\n",
    "        X1 = basin_peak_ensemble.sel(product=combo[0])['peak_swe']\n",
    "        X2 = basin_peak_ensemble.sel(product=combo[1])['peak_swe']\n",
    "        r, p = xr.apply_ufunc(pairwise_corr,X1,X2,input_core_dims=[['time'],['time']],output_core_dims=[[],[]],vectorize=True)\n",
    "        r = r.assign_coords(combo=\"+\".join(combo))\n",
    "        p = p.assign_coords(combo=\"+\".join(combo))\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "        print(combo, \"complete\")\n",
    "    rs = xr.concat(rs,dim='combo')\n",
    "    ps = xr.concat(ps,dim='combo')\n",
    "    rs.name = 'r'\n",
    "    ps.name = 'p'\n",
    "    corr_ds = xr.merge([rs,ps])\n",
    "    corr_ds.to_netcdf(os.path.join(data_dir,'basin_corr.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_peak_ensemble = xr.open_dataset(os.path.join(data_dir,'gridded_peak_ensemble.nc'))\n",
    "gridded_peak_ensemble = gridded_peak_ensemble.where(gridded_peak_ensemble['peak_swe']>0)\n",
    "gridded_peak_ensemble = gridded_peak_ensemble.where(gridded_peak_ensemble[\"peak_swe\"].count((\"product\",\"time\"))>72)\n",
    "\n",
    "# calculate ensemble spread-to-mean ratio at each timestep\n",
    "gridded_peak_max = gridded_peak_ensemble[\"peak_swe\"].max(\"product\")\n",
    "gridded_peak_min = gridded_peak_ensemble[\"peak_swe\"].min(\"product\")\n",
    "gridded_peak_mean = gridded_peak_ensemble[\"peak_swe\"].mean(\"product\")\n",
    "gridded_ens_uncert = (gridded_peak_max-gridded_peak_min) / gridded_peak_mean\n",
    "gridded_ens_uncert = gridded_ens_uncert.where(gridded_ens_uncert.max(\"time\")!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_peak_ensemble = xr.open_dataset(os.path.join(data_dir,'basin_peak_ensemble.nc'))\n",
    "basin_peak_ensemble = basin_peak_ensemble.where(basin_peak_ensemble['peak_swe']>0)\n",
    "basin_peak_ensemble = basin_peak_ensemble.where(basin_peak_ensemble[\"peak_swe\"].count((\"product\",\"time\"))>72)\n",
    "\n",
    "# calculate ensemble spread-to-mean ratio at each timestep\n",
    "basin_peak_max = basin_peak_ensemble[\"peak_swe\"].max(\"product\")\n",
    "basin_peak_min = basin_peak_ensemble[\"peak_swe\"].min(\"product\")\n",
    "basin_peak_mean = basin_peak_ensemble[\"peak_swe\"].mean(\"product\")\n",
    "basin_ens_uncert = (basin_peak_max-basin_peak_min) / basin_peak_mean\n",
    "basin_ens_uncert = basin_ens_uncert.where(basin_ens_uncert.max(\"time\")!=0)\n",
    "\n",
    "# rasterize basin values for plotting\n",
    "basin_ens_uncert = basin_ens_uncert.to_dataframe().reset_index()\n",
    "grdc_basins = gpd.read_file(os.path.join(data_dir, \"boundaries\", \"grdc_basins\"), layer=\"mrb_basins\")\n",
    "basin_ens_uncert = grdc_basins[['geometry']].merge(basin_ens_uncert,left_index=True,right_on='basin')\n",
    "basin_ens_uncert = rasterize(zip(basin_ens_uncert.geometry,basin_ens_uncert.peak_swe),gridded_peak_ensemble.drop([\"time\",\"product\"]).coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_corr = xr.open_dataset(os.path.join(data_dir,'gridded_corr.nc'))\n",
    "gridded_corr_mean = gridded_corr['r'].mean(\"combo\").where(~xr.ufuncs.isnan(gridded_ens_uncert.mean(\"time\")))\n",
    "gridded_frac_sig = (gridded_corr['p'] < 0.05).astype(int).sum(\"combo\") / gridded_corr['p'].count(\"combo\")\n",
    "gridded_frac_sig = gridded_frac_sig.where(~xr.ufuncs.isnan(gridded_ens_uncert.mean(\"time\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_corr = xr.open_dataset(os.path.join(data_dir,'basin_corr.nc'))\n",
    "basin_corr_mean = basin_corr['r'].mean(\"combo\")\n",
    "basin_frac_sig = (basin_corr['p'] < 0.05).astype(int).sum(\"combo\") / basin_corr['p'].count(\"combo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_corr_mean = basin_corr_mean.to_dataframe().reset_index()\n",
    "basin_corr_mean = grdc_basins[['geometry']].merge(basin_corr_mean,left_index=True,right_on='basin')\n",
    "basin_corr_mean = rasterize(zip(basin_corr_mean.geometry,basin_corr_mean.r),gridded_peak_ensemble.drop([\"time\",\"product\"]).coords)\n",
    "basin_corr_mean = basin_corr_mean.where(~xr.ufuncs.isnan(basin_ens_uncert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_frac_sig = basin_frac_sig.to_dataframe().reset_index()\n",
    "basin_frac_sig = grdc_basins[['geometry']].merge(basin_frac_sig,left_index=True,right_on='basin')\n",
    "basin_frac_sig = rasterize(zip(basin_frac_sig.geometry,basin_frac_sig.p),gridded_peak_ensemble.drop([\"time\",\"product\"]).coords)\n",
    "basin_frac_sig = basin_frac_sig.where(~xr.ufuncs.isnan(basin_ens_uncert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_corr = xr.open_dataset(os.path.join(data_dir,'basin_corr.nc'))\n",
    "basin_corr_mean = basin_corr['r'].mean(\"combo\").where(~xr.ufuncs.isnan(basin_ens_uncert))\n",
    "basin_frac_sig = (basin_corr['p'] < 0.05).astype(int).sum(\"combo\") / basin_corr['p'].count(\"combo\")\n",
    "basin_frac_sig = basin_frac_sig.where(~xr.ufuncs.isnan(basin_ens_uncert))\n",
    "\n",
    "basin_corr_mean = basin_corr_mean.to_dataframe().reset_index()\n",
    "basin_corr_mean = grdc_basins[['geometry']].merge(basin_corr_mean,left_index=True,right_on='basin')\n",
    "basin_corr_mean = rasterize(zip(basin_corr_mean.geometry,basin_corr_mean.r),gridded_peak_ensemble.drop([\"time\",\"product\"]).coords)\n",
    "\n",
    "basin_frac_sig = basin_frac_sig.to_dataframe().reset_index()\n",
    "basin_frac_sig = grdc_basins[['geometry']].merge(basin_frac_sig,left_index=True,right_on='basin')\n",
    "basin_frac_sig = rasterize(zip(basin_frac_sig.geometry,basin_frac_sig.p),gridded_peak_ensemble.drop([\"time\",\"product\"]).coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_ids = {k: i for i, k in enumerate(grdc_basins.RIVER_BASI)}\n",
    "basin_shapes = [(shape, n) for n, shape in enumerate(grdc_basins.geometry)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load basin ensemble\n",
    "basin_peak_ensemble = basin_peak_ensemble.to_dataframe().reset_index()\n",
    "\n",
    "# subset out same years of common overlap\n",
    "basin_peak_ensemble[\"time\"] = pd.to_datetime(basin_peak_ensemble[\"time\"])\n",
    "basin_peak_ensemble = basin_peak_ensemble[(basin_peak_ensemble.time.dt.date>=pd.to_datetime(\"2002-10-01\")) & (basin_peak_ensemble.time.dt.date<=pd.to_datetime(\"2017-10-01\"))]\n",
    "\n",
    "# calculate ensemble spread-to-mean ratio\n",
    "basin_peak_ensemble[\"peak_swe\"] = basin_peak_ensemble[\"peak_swe\"].replace(0,np.nan)\n",
    "basin_peak_stats = basin_peak_ensemble.groupby([\"basin\",\"time\"]).agg({\"peak_swe\": [\"max\",\"min\", \"mean\"]})\n",
    "basin_peak_spread = (basin_peak_stats[\"peak_swe\",\"max\"]-basin_peak_stats[\"peak_swe\",\"min\"]) / basin_peak_stats[\"peak_swe\",\"mean\"]\n",
    "basin_peak_spread.name=\"ensemble_uncertainty\"\n",
    "\n",
    "# merge with basins shapefile\n",
    "basin_ens_uncert = basin_peak_spread.reset_index().groupby(\"basin\").agg({\"ensemble_uncertainty\": \"mean\"})\n",
    "basin_ens_uncert = gpd.GeoDataFrame(basin_ens_uncert.merge(grdc_basins[[\"geometry\"]],left_index=True,right_index=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stats of pairwise correlation distributions\n",
    "gridded_r_ds = xr.open_dataset(os.path.join(data_dir,\"ensembles\",\"gridded_peak_spearmanr.nc\"))\n",
    "gridded_p_ds = xr.open_dataset(os.path.join(data_dir,\"ensembles\",\"gridded_peak_spearmanr_p.nc\"))\n",
    "\n",
    "# gridded_r_ds = xr.open_dataset(os.path.join(data_dir,\"ensembles\",\"peak_spearmanr_all_prods.nc\"))\n",
    "r_mean = gridded_r_ds['peak_swe'].mean(\"combo\").where(~xr.ufuncs.isnan(gridded_ens_uncert.mean(\"time\")))\n",
    "frac_sig = (gridded_p_ds['peak_swe'] < 0.05).astype(int).sum(\"combo\") / gridded_p_ds['peak_swe'].count(\"combo\")\n",
    "frac_sig = frac_sig.where(~xr.ufuncs.isnan(gridded_ens_uncert.mean(\"time\")))\n",
    "\n",
    "basin_r = gpd.read_file(os.path.join(data_dir,\"ensembles\",\"basin_peak_spearmanr_all_products\"))\n",
    "basin_r.set_index(\"index\",inplace=True)\n",
    "\n",
    "# rasterize basin stats\n",
    "basin_r_ds = rasterize(zip(basin_r.geometry,basin_r.r_mean),gridded_peak_ensemble.drop([\"time\",\"product\"]).coords)\n",
    "basin_r_sig = rasterize(zip(basin_r.geometry,basin_r.frac_sig),gridded_peak_ensemble.drop([\"time\",\"product\"]).coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get boundaries to indicate different numbers of products\n",
    "world_borders = gpd.read_file(os.path.join(data_dir,'boundaries',\"world_borders\"))\n",
    "na_borders = world_borders[world_borders.ISO3.isin([\"USA\",\"MEX\",\"CAN\"])].dissolve(by=\"REGION\") # North America (10)\n",
    "\n",
    "us_borders = gpd.read_file(os.path.join(data_dir,\"boundaries\",\"us_states\"))\n",
    "conus_borders = us_borders[~us_borders.STUSPS.isin([\"AK\",\"HI\",\"MP\",\"AS\",\"PR\",\"VI\",\"GU\"])].dissolve(by=\"FUNCSTAT\") # CONUS (15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_basins = basin_corr['r'].where(~xr.ufuncs.isnan(basin_corr['r'].mean(\"combo\")),drop='True')['basin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2, style=\"white\")\n",
    "mpl.rcParams['hatch.linewidth'] = 2\n",
    "fig = plt.figure(figsize=(34,13.6))\n",
    "gs = gridspec.GridSpec(ncols=2, nrows=2, figure=fig)\n",
    "\n",
    "# binned colormap for uncertainty in magnitude\n",
    "mag_cmap = plt.cm.get_cmap(\"RdBu_r\")\n",
    "mag_bounds = [1/5,1/4,1/3,1/2,1,2,3,4,5]\n",
    "mag_colors = [mag_cmap(x) for x in [0.1,0.175,0.25,0.325,0.675,0.75,0.825,0.9]]\n",
    "under = mag_cmap(0)\n",
    "over = mag_cmap(0.99)\n",
    "mag_cmap = mpl.colors.ListedColormap(mag_colors,name=\"mag_cmap\")\n",
    "mag_cmap.set_under(under)\n",
    "mag_cmap.set_over(over)\n",
    "mag_norm = mpl.colors.BoundaryNorm(boundaries=mag_bounds,ncolors=8)\n",
    "\n",
    "# binned colormap for correlations\n",
    "corr_cmap = plt.cm.get_cmap(\"Reds_r\", 10)\n",
    "corr_norm = mpl.colors.BoundaryNorm(np.arange(0,1.01,0.1),11)\n",
    "\n",
    "# plot grid-cell uncertainty\n",
    "ax1 = plt.subplot(gs[0,0],projection=ccrs.Robinson())\n",
    "ax1.set_aspect(\"equal\",\"box\")\n",
    "ax1.set_extent([-180,180,0,90], ccrs.PlateCarree())\n",
    "gridded_ens_uncert.where(~xr.ufuncs.isnan(gridded_corr_mean)).mean(\"time\").plot(ax=ax1, transform=ccrs.PlateCarree(), cmap=mag_cmap,norm=mag_norm, add_colorbar=False)\n",
    "asp = ax1.get_aspect()\n",
    "na_borders.geometry.boundary.plot(ax=ax1,transform=ccrs.PlateCarree(),color=\"indigo\") # outline regions with different numbers of products\n",
    "conus_borders.geometry.boundary.plot(ax=ax1,transform=ccrs.PlateCarree(),color=\"green\",linewidth=2)\n",
    "us_borders[us_borders.STUSPS==\"HI\"].geometry.boundary.plot(ax=ax1,transform=ccrs.PlateCarree(),color=\"black\")\n",
    "ax1.set_aspect(asp)\n",
    "\n",
    "# plot basin-scale uncertainty\n",
    "ax3 = plt.subplot(gs[1,0],projection=ccrs.Robinson())\n",
    "basin_ens_uncert.where(~xr.ufuncs.isnan(basin_corr_mean)).plot(ax=ax3, transform=ccrs.PlateCarree(), cmap=mag_cmap,norm=mag_norm, add_colorbar=False)\n",
    "grdc_basins.iloc[keep_basins].geometry.boundary.plot(ax=ax3, transform=ccrs.PlateCarree(), color=\"black\", lw=0.5) # add basin_outlines\n",
    "\n",
    "\n",
    "# plot grid-cell mean of pairwise correlation distribution\n",
    "ax2 = plt.subplot(gs[0,1],projection=ccrs.Robinson())\n",
    "gridded_corr_mean.plot(ax=ax2, transform=ccrs.PlateCarree(), cmap=corr_cmap,norm=corr_norm, add_colorbar=False)\n",
    "gridded_frac_sig.plot.contourf(ax=ax2,transform=ccrs.PlateCarree(), colors=\"none\",levels=[0,1/2,2],hatches=[\"\\\\\\\\\",None],add_colorbar=False) # add hatching where fewer than half of correlations significant\n",
    "\n",
    "# plot basin-scale uncertainty\n",
    "ax4 = plt.subplot(gs[1,1],projection=ccrs.Robinson())\n",
    "basin_corr_mean.plot(ax=ax4, transform=ccrs.PlateCarree(), cmap=corr_cmap,norm=corr_norm, add_colorbar=False)\n",
    "basin_frac_sig.plot.contourf(ax=ax4, transform=ccrs.PlateCarree(), colors=\"none\",levels=[0,1/2,2],hatches=[\"\\\\\\\\\",None],add_colorbar=False)  # add hatching where fewer than half of correlations significant\n",
    "grdc_basins.iloc[keep_basins].geometry.boundary.plot(ax=ax4, transform=ccrs.PlateCarree(), color=\"black\", lw=0.5) # add basin_outlines\n",
    "\n",
    "\n",
    "# add colorbar for uncertainty in magnitude\n",
    "mag_sm = plt.cm.ScalarMappable(cmap=mag_cmap, norm=mag_norm)\n",
    "mag_sm.set_array([])\n",
    "mag_cbar = fig.colorbar(mag_sm, ax=[ax1, ax3], orientation=\"horizontal\", ticks=mag_bounds, pad=0.05,use_gridspec=True, extend=\"both\")\n",
    "mag_cbar.ax.set_xlabel(r\"Ensemble spread-to-mean ratio\", labelpad=10)\n",
    "mag_cbar.ax.set_xticklabels([\"1/5\",\"1/4\",\"1/3\",\"1/2\",\"1/1\",\"2/1\",\"3/1\",\"4/1\",\"5/1\"])\n",
    "fig.text(0.13,0.79, \"a\",fontsize=30,fontweight=\"bold\")\n",
    "fig.text(0.13,0.46, \"c\",fontsize=30,fontweight=\"bold\")\n",
    "\n",
    "# add colorbar for average correlation\n",
    "corr_sm = plt.cm.ScalarMappable(cmap=corr_cmap, norm=corr_norm)\n",
    "corr_sm.set_array([])\n",
    "corr_cbar = fig.colorbar(corr_sm, ax=[ax2, ax4], orientation=\"horizontal\", ticks = np.arange(0,1.01,0.1), pad=0.05,use_gridspec=True)\n",
    "corr_cbar.ax.set_xlabel(r\"Mean pairwise Spearman's $\\rho$\", labelpad=10)\n",
    "corr_cbar.ax.set_xticklabels([np.round(0.1*i,1) for i in range(11)])\n",
    "fig.text(0.552,0.79, \"b\",fontsize=30,fontweight=\"bold\")\n",
    "fig.text(0.552,0.46, \"d\",fontsize=30,fontweight=\"bold\")\n",
    "\n",
    "fig.text(0.1, 0.73, \"Grid cell\", fontsize=28, rotation=90, va=\"center\")\n",
    "fig.text(0.1, 0.4, \"Basin\", fontsize=28, rotation=90, va=\"center\")\n",
    "fig.text(0.3, 0.84, \"Average Ensemble Uncertainty in Peak SWE\", fontsize=28, ha=\"center\")\n",
    "fig.text(0.73, 0.84, \"Ensemble Agreement on Temporal Ranks of Peak SWE\", fontsize=28, ha=\"center\")\n",
    "\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.set_extent([-180,180,10,85], ccrs.PlateCarree())\n",
    "    ax.coastlines('110m')\n",
    "    ax.add_feature(cartopy.feature.OCEAN, facecolor=\"white\")\n",
    "    ax.add_feature(cartopy.feature.LAKES, facecolor=\"grey\",alpha=0.1)\n",
    "    ax.title.set_text(\"\")\n",
    "    ax.set_aspect(\"equal\",\"box\")\n",
    "    ax.add_feature(cartopy.feature.LAND, facecolor=\"grey\",alpha=0.3)\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir, \"fig2.pdf\"),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arg",
   "language": "python",
   "name": "arg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
